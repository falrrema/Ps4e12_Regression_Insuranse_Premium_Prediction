{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensembling Autogluon OOFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from autogluon.core.metrics import make_scorer\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import root_mean_squared_log_error, root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pio.templates.default = \"simple_white\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import specific libraries\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cv_rmsle(y_true, y_pred, n_folds=10):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (_, val_idx) in enumerate(kf.split(y_true)):\n",
    "        fold_rmsle = root_mean_squared_log_error(\n",
    "            y_true.iloc[val_idx],\n",
    "            y_pred.iloc[val_idx]\n",
    "        )\n",
    "        fold_scores.append(fold_rmsle)\n",
    "    \n",
    "    return {\n",
    "        'cv_scores': fold_scores,\n",
    "        'mean_cv': np.mean(fold_scores),\n",
    "        'std_cv': np.std(fold_scores)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getenv('DATA_FOLDER_PATH', 'Data/')\n",
    "#base_path = os.getenv('DATA_FOLDER_PATH', '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e12_Regression_Insuranse_Premium_Prediction/Data/')\n",
    "\n",
    "train = pd.read_parquet(os.path.join(base_path, 'train_transformed.parquet'))\n",
    "test = pd.read_parquet(os.path.join(base_path, 'test_transformed.parquet'))\n",
    "submission = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n",
    "original = pd.read_csv(os.path.join(base_path, 'Insurance Premium Prediction Dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading OOFs\n",
    "oof_12hr_nonlog_local = pd.read_parquet(\"Data/oofs/oof_preds_12nonlog.parquet\")\n",
    "oof_4hr_log_tpu = pd.read_parquet(\"Data/oofs/oof_preds_4log.parquet\")\n",
    "\n",
    "# Fusing\n",
    "oof_12hr_nonlog_local.set_index('id', inplace=True)\n",
    "train_oofs = ( train[['premium_amount']]\n",
    "              .merge(oof_12hr_nonlog_local, left_index=True, right_index=True)\n",
    "              .merge(oof_4hr_log_tpu, left_index=True, right_index=True) \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV scores for each OOF prediction\n",
    "oof_columns = train_oofs.columns[1:]  # Skip the first column (premium_amount)\n",
    "cv_results = {}\n",
    "for col in oof_columns:\n",
    "    scores = calculate_cv_rmsle(\n",
    "        train_oofs['premium_amount'],\n",
    "        train_oofs[col],\n",
    "        n_folds=5\n",
    "    )\n",
    "    cv_results[col] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean RMSLE</th>\n",
       "      <th>Std RMSLE</th>\n",
       "      <th>n_folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4log_WeightedEnsemble_L4</td>\n",
       "      <td>1.044443</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4log_WeightedEnsemble_L3</td>\n",
       "      <td>1.044464</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4log_LightGBM_r131_BAG_L3</td>\n",
       "      <td>1.044553</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4log_CatBoost_BAG_L3</td>\n",
       "      <td>1.044553</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4log_LightGBM_BAG_L3</td>\n",
       "      <td>1.044560</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12nonlog_XGBoost_r33_BAG_L1</td>\n",
       "      <td>1.170174</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4log_KNeighborsDist_BAG_L1</td>\n",
       "      <td>1.201113</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4log_KNeighborsUnif_BAG_L1</td>\n",
       "      <td>1.201113</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12nonlog_KNeighborsUnif_BAG_L1</td>\n",
       "      <td>1.207578</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12nonlog_KNeighborsDist_BAG_L1</td>\n",
       "      <td>1.207581</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Mean RMSLE  Std RMSLE  n_folds\n",
       "26        4log_WeightedEnsemble_L4    1.044443   0.002046        5\n",
       "27        4log_WeightedEnsemble_L3    1.044464   0.002612        5\n",
       "28       4log_LightGBM_r131_BAG_L3    1.044553   0.001178        5\n",
       "29            4log_CatBoost_BAG_L3    1.044553   0.001622        5\n",
       "30            4log_LightGBM_BAG_L3    1.044560   0.000830        5\n",
       "..                             ...         ...        ...      ...\n",
       "23     12nonlog_XGBoost_r33_BAG_L1    1.170174   0.002048        5\n",
       "64      4log_KNeighborsDist_BAG_L1    1.201113   0.002137        5\n",
       "63      4log_KNeighborsUnif_BAG_L1    1.201113   0.001864        5\n",
       "24  12nonlog_KNeighborsUnif_BAG_L1    1.207578   0.003399        5\n",
       "25  12nonlog_KNeighborsDist_BAG_L1    1.207581   0.001936        5\n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary table\n",
    "cv_summary = pd.DataFrame([{\n",
    "    'Model': model,\n",
    "    'Mean RMSLE': scores['mean_cv'],\n",
    "    'Std RMSLE': scores['std_cv'], \n",
    "    'n_folds': len(scores['cv_scores'])\n",
    "} for model, scores in cv_results.items()])\n",
    "\n",
    "cv_summary = cv_summary.sort_values('Mean RMSLE')\n",
    "cv_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class BaggedEnsembleSelection:\n",
    "    def __init__(self, n_init=5, max_iter=30, decimals=5, corr_threshold=0.7, \n",
    "                 bag_fraction=0.25, epsilon=0.00001, warm_start=10):\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.decimals = decimals\n",
    "        self.corr_threshold = corr_threshold\n",
    "        self.bag_fraction = bag_fraction\n",
    "        self.epsilon = epsilon\n",
    "        self.warm_start = warm_start\n",
    "        self.best_models = None\n",
    "        self.best_weights = None\n",
    "        self.best_performance = None\n",
    "    \n",
    "    def get_diverse_init_models(self, model_performances, model_cols, corr_matrix):\n",
    "        \"\"\"Get initial diverse models based on correlation threshold\"\"\"\n",
    "        # Start with best model\n",
    "        init_models = [model_performances.idxmax()]\n",
    "        available_models = list(model_cols)\n",
    "        available_models.remove(init_models[0])\n",
    "        \n",
    "        while len(init_models) < self.n_init and available_models:\n",
    "            # Remove highly correlated models using vectorized operations\n",
    "            corr_with_selected = corr_matrix.loc[available_models, init_models].max(axis=1)\n",
    "            available_models = [m for m, c in zip(available_models, corr_with_selected) \n",
    "                              if c <= self.corr_threshold]\n",
    "            \n",
    "            if not available_models:\n",
    "                break\n",
    "                \n",
    "            # Add best remaining model\n",
    "            best_model = model_performances[available_models].idxmax()\n",
    "            init_models.append(best_model)\n",
    "            available_models.remove(best_model)\n",
    "            \n",
    "        return init_models\n",
    "    \n",
    "    def get_ensemble_preds(self, X, ensemble):\n",
    "        \"\"\"Get predictions for current ensemble using vectorized operations\"\"\"\n",
    "        if not ensemble:\n",
    "            return np.zeros(len(X))\n",
    "            \n",
    "        ensemble_weights = pd.Series(ensemble) / sum(ensemble.values())\n",
    "        return X[ensemble_weights.index].multiply(ensemble_weights).sum(axis=1)\n",
    "    \n",
    "    def fit(self, X, y, performance_func):\n",
    "        \"\"\"\n",
    "        Fit ensemble using forward selection with bagging\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pd.DataFrame\n",
    "            DataFrame containing model predictions as columns\n",
    "        y : pd.Series\n",
    "            True target values\n",
    "        performance_func : callable\n",
    "            Function that takes (y_true, y_pred) and returns a score to maximize\n",
    "        \"\"\"\n",
    "        model_cols = X.columns\n",
    "        n_samples = len(y)\n",
    "        \n",
    "        # Calculate initial model performances\n",
    "        model_performances = pd.Series({\n",
    "        col: performance_func(y, X[col]) for col in model_cols\n",
    "        })\n",
    "        \n",
    "        best_single = model_performances.max()\n",
    "        print(f\"Best single model performance: {best_single:.5f} | Model: {model_performances.idxmax()}\")\n",
    "\n",
    "        # Get diverse initial models\n",
    "        if self.n_init > 1:\n",
    "            corr_matrix = X.corr().abs()\n",
    "            init_models = self.get_diverse_init_models(model_performances, model_cols, corr_matrix)\n",
    "        else:\n",
    "            init_models = [model_performances.idxmax()]\n",
    "            \n",
    "        # Initialize ensemble\n",
    "        ensemble = Counter(init_models)\n",
    "        current_preds = self.get_ensemble_preds(X, ensemble)\n",
    "        current_performance = performance_func(y, current_preds)\n",
    "        print(f\"Initial performance: {current_performance:.5f} | Models: {init_models}\")\n",
    "        \n",
    "        # Track best ensemble\n",
    "        best_ensemble = ensemble.copy()\n",
    "        best_mean_performance = float('-inf')\n",
    "        best_iteration = 0\n",
    "        \n",
    "        # Early stopping variables\n",
    "        bag_scores = []\n",
    "        consecutive_decreases = 0\n",
    "        previous_mean_score = float('-inf')\n",
    "        \n",
    "        # Greedy forward selection with bagging\n",
    "        bag_size = int(n_samples * self.bag_fraction)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            # Sample indices for this iteration\n",
    "            bag_indices = np.random.choice(n_samples, size=bag_size, replace=False)\n",
    "            \n",
    "            # Get current ensemble size\n",
    "            n_models = sum(ensemble.values())\n",
    "            \n",
    "            # Convert to numpy arrays before multi-dimensional indexing\n",
    "            current_preds_np = current_preds.to_numpy() if isinstance(current_preds, pd.Series) else current_preds\n",
    "            X_np = X.values\n",
    "            \n",
    "            # Vectorized calculation of all candidate predictions\n",
    "            current_preds_expanded = current_preds_np[:, np.newaxis]\n",
    "            candidate_preds = (n_models * current_preds_expanded + X_np) / (n_models + 1)\n",
    "            \n",
    "            # Calculate scores for all candidates at once\n",
    "            candidate_scores = {\n",
    "                model: performance_func(y.iloc[bag_indices], candidate_preds[bag_indices, j])\n",
    "                for j, model in enumerate(model_cols)\n",
    "            }\n",
    "            \n",
    "            best_model = max(candidate_scores.items(), key=lambda x: x[1])[0]\n",
    "            best_score = candidate_scores[best_model]\n",
    "            \n",
    "            # Update ensemble\n",
    "            ensemble.update({best_model: 1})\n",
    "            current_preds = self.get_ensemble_preds(X, ensemble)\n",
    "            full_performance = performance_func(y, current_preds)\n",
    "            \n",
    "            # Early stopping check\n",
    "            bag_scores.append(best_score)\n",
    "            current_mean_score = np.mean(bag_scores[-self.warm_start:])\n",
    "            \n",
    "            if i >= self.warm_start:\n",
    "                if current_mean_score < previous_mean_score:\n",
    "                    consecutive_decreases += 1\n",
    "                    if consecutive_decreases >= 3:\n",
    "                        print(f\"\\nEarly stopping triggered at iteration {i+1}\")\n",
    "                        break\n",
    "                else:\n",
    "                    consecutive_decreases = 0\n",
    "                \n",
    "                if current_mean_score > best_mean_performance:\n",
    "                    best_mean_performance = current_mean_score\n",
    "                    best_ensemble = ensemble.copy()\n",
    "                    best_iteration = i + 1\n",
    "                    \n",
    "            previous_mean_score = current_mean_score\n",
    "            \n",
    "            print(f\"Iteration {i+1}: Added {best_model}, Bag Score: {best_score:.5f}, \"\n",
    "                  f\"Mean Bag Score: {current_mean_score:.5f}, Full Score: {full_performance:.5f}\")\n",
    "        \n",
    "        # Convert counter to weights\n",
    "        total_count = sum(best_ensemble.values())\n",
    "        self.best_weights = pd.Series(best_ensemble) / total_count\n",
    "        self.best_models = self.best_weights.index\n",
    "        self.best_mean_performance = best_mean_performance\n",
    "        \n",
    "        print(\"\\nFinal Ensemble Weights:\")\n",
    "        for model, weight in self.best_weights.sort_values(ascending=False).items():\n",
    "            print(f\"{model}: {weight:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_best_ensemble(self):\n",
    "        \"\"\"Return DataFrame with models and their weights\"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'model': self.best_weights.index,\n",
    "            'weight': self.best_weights.values\n",
    "        }).sort_values('weight', ascending=False)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"Generate ensemble predictions for new data\"\"\"\n",
    "        if self.best_weights is None:\n",
    "            raise ValueError(\"Model must be fitted before making predictions\")\n",
    "        return (X[self.best_models] * self.best_weights.values).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit\n",
    "model_cols = train_oofs.columns[1:]  # All columns except premium_amount\n",
    "ensembler = BaggedEnsembleSelection(n_init=2, max_iter=50, corr_threshold=0.7, bag_fraction=0.25, warm_start=10)\n",
    "ensembler.fit(train_oofs[model_cols], train_oofs['premium_amount'], performance_func=lambda y, pred: -root_mean_squared_log_error(y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log10 transformation to all model predictions\n",
    "train_oofs[train_oofs.columns] = np.log10(train_oofs[train_oofs.columns].clip(lower=1e-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best single model performance: -0.45617 | Model: 4log_WeightedEnsemble_L4\n",
      "Initial performance: -0.46257 | Models: ['4log_WeightedEnsemble_L4', '12nonlog_NeuralNetTorch_BAG_L2']\n",
      "Iteration 1: Added 4log_NeuralNetFastAI_BAG_L3, Bag Score: -0.45747, Mean Bag Score: -0.45747, Full Score: -0.45901\n",
      "Iteration 2: Added 4log_WeightedEnsemble_L3, Bag Score: -0.45808, Mean Bag Score: -0.45777, Full Score: -0.45777\n",
      "Iteration 3: Added 4log_RandomForestMSE_BAG_L2, Bag Score: -0.45661, Mean Bag Score: -0.45738, Full Score: -0.45721\n",
      "Iteration 4: Added 4log_NeuralNetFastAI_r191_BAG_L2, Bag Score: -0.45518, Mean Bag Score: -0.45683, Full Score: -0.45689\n",
      "Iteration 5: Added 4log_ExtraTreesMSE_BAG_L3, Bag Score: -0.45688, Mean Bag Score: -0.45684, Full Score: -0.45670\n",
      "Iteration 6: Added 4log_NeuralNetFastAI_BAG_L3, Bag Score: -0.45670, Mean Bag Score: -0.45682, Full Score: -0.45658\n",
      "Iteration 7: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45755, Mean Bag Score: -0.45692, Full Score: -0.45649\n",
      "Iteration 8: Added 4log_LightGBM_r131_BAG_L3, Bag Score: -0.45624, Mean Bag Score: -0.45684, Full Score: -0.45643\n",
      "Iteration 9: Added 4log_RandomForestMSE_BAG_L3, Bag Score: -0.45525, Mean Bag Score: -0.45666, Full Score: -0.45639\n",
      "Iteration 10: Added 4log_LightGBM_r131_BAG_L2, Bag Score: -0.45656, Mean Bag Score: -0.45665, Full Score: -0.45636\n",
      "Iteration 11: Added 4log_LightGBMLarge_BAG_L2, Bag Score: -0.45667, Mean Bag Score: -0.45665, Full Score: -0.45633\n",
      "Iteration 12: Added 4log_CatBoost_r177_BAG_L2, Bag Score: -0.45614, Mean Bag Score: -0.45661, Full Score: -0.45631\n",
      "Iteration 13: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45608, Mean Bag Score: -0.45657, Full Score: -0.45629\n",
      "Iteration 14: Added 4log_LightGBM_r131_BAG_L3, Bag Score: -0.45624, Mean Bag Score: -0.45654, Full Score: -0.45628\n",
      "Iteration 15: Added 4log_RandomForestMSE_BAG_L2, Bag Score: -0.45784, Mean Bag Score: -0.45663, Full Score: -0.45627\n",
      "Iteration 16: Added 4log_ExtraTreesMSE_BAG_L2, Bag Score: -0.45533, Mean Bag Score: -0.45655, Full Score: -0.45626\n",
      "Iteration 17: Added 4log_CatBoost_r177_BAG_L2, Bag Score: -0.45685, Mean Bag Score: -0.45657, Full Score: -0.45625\n",
      "Iteration 18: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45663, Mean Bag Score: -0.45657, Full Score: -0.45624\n",
      "Iteration 19: Added 4log_LightGBMLarge_BAG_L2, Bag Score: -0.45716, Mean Bag Score: -0.45660, Full Score: -0.45624\n",
      "Iteration 20: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45657, Mean Bag Score: -0.45660, Full Score: -0.45623\n",
      "Iteration 21: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45774, Mean Bag Score: -0.45661, Full Score: -0.45623\n",
      "Iteration 22: Added 4log_NeuralNetFastAI_BAG_L2, Bag Score: -0.45717, Mean Bag Score: -0.45657, Full Score: -0.45622\n",
      "Iteration 23: Added 4log_CatBoost_r9_BAG_L2, Bag Score: -0.45631, Mean Bag Score: -0.45655, Full Score: -0.45622\n",
      "Iteration 24: Added 4log_ExtraTreesMSE_BAG_L2, Bag Score: -0.45642, Mean Bag Score: -0.45662, Full Score: -0.45622\n",
      "Iteration 25: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45667, Mean Bag Score: -0.45661, Full Score: -0.45621\n",
      "Iteration 26: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45581, Mean Bag Score: -0.45656, Full Score: -0.45621\n",
      "Iteration 27: Added 4log_ExtraTreesMSE_BAG_L2, Bag Score: -0.45665, Mean Bag Score: -0.45652, Full Score: -0.45621\n",
      "Iteration 28: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45633, Mean Bag Score: -0.45652, Full Score: -0.45621\n",
      "Iteration 29: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45716, Mean Bag Score: -0.45662, Full Score: -0.45621\n",
      "Iteration 30: Added 4log_RandomForestMSE_BAG_L2, Bag Score: -0.45653, Mean Bag Score: -0.45661, Full Score: -0.45620\n",
      "Iteration 31: Added 4log_LightGBMLarge_BAG_L2, Bag Score: -0.45547, Mean Bag Score: -0.45655, Full Score: -0.45620\n",
      "Iteration 32: Added 4log_RandomForestMSE_BAG_L3, Bag Score: -0.45536, Mean Bag Score: -0.45652, Full Score: -0.45620\n",
      "Iteration 33: Added 4log_RandomForestMSE_BAG_L2, Bag Score: -0.45565, Mean Bag Score: -0.45649, Full Score: -0.45620\n",
      "Iteration 34: Added 4log_LightGBM_r131_BAG_L3, Bag Score: -0.45545, Mean Bag Score: -0.45646, Full Score: -0.45620\n",
      "Iteration 35: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45682, Mean Bag Score: -0.45640, Full Score: -0.45620\n",
      "Iteration 36: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45612, Mean Bag Score: -0.45644, Full Score: -0.45620\n",
      "Iteration 37: Added 4log_NeuralNetFastAI_BAG_L3, Bag Score: -0.45683, Mean Bag Score: -0.45644, Full Score: -0.45620\n",
      "Iteration 38: Added 4log_CatBoost_BAG_L2, Bag Score: -0.45700, Mean Bag Score: -0.45646, Full Score: -0.45620\n",
      "Iteration 39: Added 4log_LightGBMLarge_BAG_L2, Bag Score: -0.45568, Mean Bag Score: -0.45639, Full Score: -0.45619\n",
      "Iteration 40: Added 4log_NeuralNetFastAI_BAG_L2, Bag Score: -0.45435, Mean Bag Score: -0.45628, Full Score: -0.45619\n",
      "Iteration 41: Added 4log_LightGBMLarge_BAG_L2, Bag Score: -0.45696, Mean Bag Score: -0.45624, Full Score: -0.45619\n",
      "Iteration 42: Added 4log_RandomForestMSE_BAG_L1, Bag Score: -0.45463, Mean Bag Score: -0.45611, Full Score: -0.45619\n",
      "Iteration 43: Added 4log_ExtraTreesMSE_BAG_L3, Bag Score: -0.45544, Mean Bag Score: -0.45607, Full Score: -0.45619\n",
      "Iteration 44: Added 4log_CatBoost_r177_BAG_L2, Bag Score: -0.45669, Mean Bag Score: -0.45608, Full Score: -0.45619\n",
      "Iteration 45: Added 4log_LightGBM_BAG_L2, Bag Score: -0.45485, Mean Bag Score: -0.45599, Full Score: -0.45619\n",
      "Iteration 46: Added 4log_LightGBM_BAG_L3, Bag Score: -0.45576, Mean Bag Score: -0.45599, Full Score: -0.45619\n",
      "Iteration 47: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45582, Mean Bag Score: -0.45595, Full Score: -0.45619\n",
      "Iteration 48: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45675, Mean Bag Score: -0.45597, Full Score: -0.45619\n",
      "Iteration 49: Added 4log_LightGBMXT_BAG_L2, Bag Score: -0.45683, Mean Bag Score: -0.45595, Full Score: -0.45619\n",
      "Iteration 50: Added 4log_LightGBMLarge_BAG_L3, Bag Score: -0.45678, Mean Bag Score: -0.45596, Full Score: -0.45619\n",
      "\n",
      "Final Ensemble Weights:\n",
      "4log_LightGBMLarge_BAG_L3: 0.1429\n",
      "4log_CatBoost_BAG_L2: 0.1224\n",
      "4log_LightGBMLarge_BAG_L2: 0.1020\n",
      "4log_RandomForestMSE_BAG_L2: 0.0816\n",
      "4log_NeuralNetFastAI_BAG_L3: 0.0612\n",
      "4log_LightGBM_r131_BAG_L3: 0.0612\n",
      "4log_CatBoost_r177_BAG_L2: 0.0612\n",
      "4log_ExtraTreesMSE_BAG_L2: 0.0612\n",
      "4log_NeuralNetFastAI_BAG_L2: 0.0408\n",
      "4log_ExtraTreesMSE_BAG_L3: 0.0408\n",
      "4log_RandomForestMSE_BAG_L3: 0.0408\n",
      "4log_WeightedEnsemble_L4: 0.0204\n",
      "4log_LightGBM_BAG_L2: 0.0204\n",
      "4log_RandomForestMSE_BAG_L1: 0.0204\n",
      "4log_CatBoost_r9_BAG_L2: 0.0204\n",
      "4log_LightGBM_r131_BAG_L2: 0.0204\n",
      "12nonlog_NeuralNetTorch_BAG_L2: 0.0204\n",
      "4log_NeuralNetFastAI_r191_BAG_L2: 0.0204\n",
      "4log_WeightedEnsemble_L3: 0.0204\n",
      "4log_LightGBM_BAG_L3: 0.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BaggedEnsembleSelection at 0x2d4c47c40>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit\n",
    "ensembler = BaggedEnsembleSelection(n_init=2, max_iter=50, corr_threshold=0.7, bag_fraction=0.2, warm_start=20)\n",
    "ensembler.fit(train_oofs[model_cols], train_oofs['premium_amount'], performance_func=lambda y, pred: -root_mean_squared_error(y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oofs['ensemble_preds'] = ensembler.predict(train_oofs[model_cols])\n",
    "\n",
    "# Convert back from log10 to original scale\n",
    "train_oofs[train_oofs.columns] = 10 ** train_oofs[train_oofs.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0444705356658068"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_mean_squared_log_error(train_oofs['premium_amount'], train_oofs['ensemble_preds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Understanding model errors**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (train_oofs[['premium_amount', '4log_WeightedEnsemble_L4']]\n",
    " .assign(premium_amount_log = lambda x: np.log10(x['premium_amount']))\n",
    " .assign(preds_log = lambda x: np.log10(x['4log_WeightedEnsemble_L4']))\n",
    " .assign(error = lambda x: x['premium_amount_log'] - x['preds_log'])\n",
    " .assign(error_squared = lambda x: x['error'] ** 2)\n",
    " .sort_values('error_squared', ascending=False)\n",
    " )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of squared errors:\n",
      "                 count  percentage\n",
      "error_squared                     \n",
      "< 1            1135263   94.605250\n",
      "1-1.5            14054    1.171167\n",
      "1.5-2            25638    2.136500\n",
      "> 2              25045    2.087083\n"
     ]
    }
   ],
   "source": [
    "# Create error bins\n",
    "error_bins = pd.cut(errors['error_squared'], \n",
    "                   bins=[0, 1, 1.5, 2, float('inf')],\n",
    "                   labels=['< 1', '1-1.5', '1.5-2', '> 2'],\n",
    "                   include_lowest=True)\n",
    "\n",
    "# Group by error bins and get counts\n",
    "error_distribution = pd.DataFrame({\n",
    "    'count': error_bins.value_counts(),\n",
    "    'percentage': error_bins.value_counts(normalize=True) * 100\n",
    "}).sort_index()\n",
    "\n",
    "print(\"\\nDistribution of squared errors:\")\n",
    "print(error_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782893142875139"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_small = errors[errors['error_squared'] < 1]\n",
    "root_mean_squared_log_error(errors_small['premium_amount'], errors_small['4log_WeightedEnsemble_L4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_4log = pd.read_csv('Data/submissions/submission_WeightedEnsemble_L4_4hr_log_tpu.csv')\n",
    "submission_12nonlog = pd.read_csv('Data/submissions/submission_WeightedEnsemble_L3_12hr_nonlog_local.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_4log = submission_4log.set_index('id').rename(columns={'Premium Amount': '4log_WeightedEnsemble_L4'})\n",
    "submission_12nonlog = submission_12nonlog.set_index('id').rename(columns={'Premium Amount': '12nonlog_WeightedEnsemble_L3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4log_WeightedEnsemble_L4</th>\n",
       "      <th>12nonlog_WeightedEnsemble_L3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200000</th>\n",
       "      <td>825.73157</td>\n",
       "      <td>929.62250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200001</th>\n",
       "      <td>813.55566</td>\n",
       "      <td>912.69617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200002</th>\n",
       "      <td>801.74110</td>\n",
       "      <td>854.73520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200003</th>\n",
       "      <td>812.36896</td>\n",
       "      <td>878.03625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200004</th>\n",
       "      <td>753.27423</td>\n",
       "      <td>848.68390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>966.78390</td>\n",
       "      <td>957.26044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>567.34860</td>\n",
       "      <td>1003.26294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>816.53296</td>\n",
       "      <td>885.10284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>824.32794</td>\n",
       "      <td>925.06720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>795.21190</td>\n",
       "      <td>880.76340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4log_WeightedEnsemble_L4  12nonlog_WeightedEnsemble_L3\n",
       "id                                                             \n",
       "1200000                 825.73157                     929.62250\n",
       "1200001                 813.55566                     912.69617\n",
       "1200002                 801.74110                     854.73520\n",
       "1200003                 812.36896                     878.03625\n",
       "1200004                 753.27423                     848.68390\n",
       "...                           ...                           ...\n",
       "1999995                 966.78390                     957.26044\n",
       "1999996                 567.34860                    1003.26294\n",
       "1999997                 816.53296                     885.10284\n",
       "1999998                 824.32794                     925.06720\n",
       "1999999                 795.21190                     880.76340\n",
       "\n",
       "[800000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_oofs = submission_4log.merge(submission_12nonlog, left_index=True, right_index=True)\n",
    "submission_oofs.to_csv('Data/oofs/test_oofs.csv')\n",
    "submission_oofs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
