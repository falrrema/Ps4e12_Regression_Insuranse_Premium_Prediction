{"cells":[{"cell_type":"code","execution_count":1,"id":"145a95a0","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-30T13:55:51.219984Z","iopub.status.busy":"2024-12-30T13:55:51.219725Z","iopub.status.idle":"2024-12-30T13:56:23.566606Z","shell.execute_reply":"2024-12-30T13:56:23.565580Z"},"papermill":{"duration":32.353827,"end_time":"2024-12-30T13:56:23.568507","exception":false,"start_time":"2024-12-30T13:55:51.214680","status":"completed"},"tags":[],"id":"145a95a0","executionInfo":{"status":"ok","timestamp":1735604538740,"user_tz":180,"elapsed":38979,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["%%capture\n","%pip install setuptools wheel autogluon.tabular[all] dask[dataframe]\n","%pip install -U -q ipywidgets\n","%pip install -U scikit-learn"]},{"cell_type":"code","execution_count":2,"id":"5d598603","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:23.577061Z","iopub.status.busy":"2024-12-30T13:56:23.576785Z","iopub.status.idle":"2024-12-30T13:56:26.927666Z","shell.execute_reply":"2024-12-30T13:56:26.926980Z"},"papermill":{"duration":3.356501,"end_time":"2024-12-30T13:56:26.929156","exception":false,"start_time":"2024-12-30T13:56:23.572655","status":"completed"},"tags":[],"id":"5d598603","executionInfo":{"status":"ok","timestamp":1735604543336,"user_tz":180,"elapsed":4601,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["# Import basic libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import warnings\n","import cloudpickle\n","import plotly.io as pio\n","import plotly.graph_objects as go\n","from autogluon.core.metrics import make_scorer\n","import sklearn\n","from plotly.subplots import make_subplots\n","pd.options.plotting.backend = \"plotly\"\n","pio.templates.default = \"simple_white\"\n","warnings.filterwarnings('ignore')\n","\n","# Import specific libraries\n","from autogluon.tabular import TabularDataset, TabularPredictor"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-UVxFOcFx_0","executionInfo":{"status":"ok","timestamp":1735604560680,"user_tz":180,"elapsed":17349,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"ce4b9f99-e927-4e03-d5e2-3dcdf751e21c"},"id":"X-UVxFOcFx_0","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":16,"id":"9f14d1cc","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:26.937555Z","iopub.status.busy":"2024-12-30T13:56:26.937113Z","iopub.status.idle":"2024-12-30T13:56:37.802478Z","shell.execute_reply":"2024-12-30T13:56:37.801676Z"},"papermill":{"duration":10.871295,"end_time":"2024-12-30T13:56:37.804160","exception":false,"start_time":"2024-12-30T13:56:26.932865","status":"completed"},"tags":[],"id":"9f14d1cc","executionInfo":{"status":"ok","timestamp":1735604728550,"user_tz":180,"elapsed":11219,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["base_path = os.getenv('DATA_FOLDER_PATH', '/content/drive/MyDrive/DS_Projects/Playground_Series/Ps4e12_Regression_Insuranse_Premium_Prediction/Data/')\n","train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n","test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n","submission = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n","original = pd.read_csv(os.path.join(base_path, 'Insurance Premium Prediction Dataset.csv'))\n","train_oofs = pd.read_csv(os.path.join(base_path, 'oofs/top_oofs_models.csv'))\n","test_oofs = pd.read_csv(os.path.join(base_path, 'oofs/test_oofs.csv'))"]},{"cell_type":"markdown","id":"8e6ac6be","metadata":{"papermill":{"duration":0.003406,"end_time":"2024-12-30T13:56:37.811610","exception":false,"start_time":"2024-12-30T13:56:37.808204","status":"completed"},"tags":[],"id":"8e6ac6be"},"source":["Lets prepare de datasets"]},{"cell_type":"code","execution_count":17,"id":"d4dbdabf","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:37.819610Z","iopub.status.busy":"2024-12-30T13:56:37.819340Z","iopub.status.idle":"2024-12-30T13:56:37.920628Z","shell.execute_reply":"2024-12-30T13:56:37.919752Z"},"papermill":{"duration":0.107048,"end_time":"2024-12-30T13:56:37.922006","exception":false,"start_time":"2024-12-30T13:56:37.814958","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":640},"id":"d4dbdabf","executionInfo":{"status":"ok","timestamp":1735604744508,"user_tz":180,"elapsed":282,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"a69b4bd4-51e5-437b-a51b-e835e96f1d39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          age  gender  annual_income marital_status  number_of_dependents  \\\n","id                                                                          \n","0        19.0  Female        10049.0        Married                   1.0   \n","1        39.0  Female        31678.0       Divorced                   3.0   \n","2        23.0    Male        25602.0       Divorced                   3.0   \n","3        21.0    Male       141855.0        Married                   2.0   \n","4        21.0    Male        39651.0         Single                   1.0   \n","...       ...     ...            ...            ...                   ...   \n","1199995  36.0  Female        27316.0        Married                   0.0   \n","1199996  54.0    Male        35786.0       Divorced                   NaN   \n","1199997  19.0    Male        51884.0       Divorced                   0.0   \n","1199998  55.0    Male            NaN         Single                   1.0   \n","1199999  21.0  Female            NaN       Divorced                   0.0   \n","\n","        education_level     occupation  health_score  location    policy_type  \\\n","id                                                                              \n","0            Bachelor's  Self-Employed     22.598761     Urban        Premium   \n","1              Master's            NaN     15.569731     Rural  Comprehensive   \n","2           High School  Self-Employed     47.177549  Suburban        Premium   \n","3            Bachelor's            NaN     10.938144     Rural          Basic   \n","4            Bachelor's  Self-Employed     20.376094     Rural        Premium   \n","...                 ...            ...           ...       ...            ...   \n","1199995        Master's     Unemployed     13.772907     Urban        Premium   \n","1199996        Master's  Self-Employed     11.483482     Rural  Comprehensive   \n","1199997        Master's            NaN     14.724469  Suburban          Basic   \n","1199998             PhD            NaN     18.547381  Suburban        Premium   \n","1199999             PhD            NaN     10.125323     Rural        Premium   \n","\n","         previous_claims  vehicle_age  credit_score  insurance_duration  \\\n","id                                                                        \n","0                    2.0         17.0         372.0                 5.0   \n","1                    1.0         12.0         694.0                 2.0   \n","2                    1.0         14.0           NaN                 3.0   \n","3                    1.0          0.0         367.0                 1.0   \n","4                    0.0          8.0         598.0                 4.0   \n","...                  ...          ...           ...                 ...   \n","1199995              NaN          5.0         372.0                 3.0   \n","1199996              NaN         10.0         597.0                 4.0   \n","1199997              0.0         19.0           NaN                 6.0   \n","1199998              1.0          7.0         407.0                 4.0   \n","1199999              0.0         18.0         502.0                 6.0   \n","\n","                  policy_start_date customer_feedback smoking_status  \\\n","id                                                                     \n","0        2023-12-23 15:21:39.134960              Poor             No   \n","1        2023-06-12 15:21:39.111551           Average            Yes   \n","2        2023-09-30 15:21:39.221386              Good            Yes   \n","3        2024-06-12 15:21:39.226954              Poor            Yes   \n","4        2021-12-01 15:21:39.252145              Poor            Yes   \n","...                             ...               ...            ...   \n","1199995  2023-05-03 15:21:39.257696              Poor             No   \n","1199996  2022-09-10 15:21:39.134960              Poor             No   \n","1199997  2021-05-25 15:21:39.106582              Good             No   \n","1199998  2021-09-19 15:21:39.190215              Poor             No   \n","1199999  2020-08-26 15:21:39.155231              Good            Yes   \n","\n","        exercise_frequency property_type  premium_amount  \n","id                                                        \n","0                   Weekly         House          2869.0  \n","1                  Monthly         House          1483.0  \n","2                   Weekly         House           567.0  \n","3                    Daily     Apartment           765.0  \n","4                   Weekly         House          2022.0  \n","...                    ...           ...             ...  \n","1199995              Daily     Apartment          1303.0  \n","1199996             Weekly     Apartment           821.0  \n","1199997            Monthly         Condo           371.0  \n","1199998              Daily     Apartment           596.0  \n","1199999            Monthly         House          2480.0  \n","\n","[1200000 rows x 20 columns]"],"text/html":["\n","  <div id=\"df-761923df-b91a-46cf-aebd-46c8681f5799\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>annual_income</th>\n","      <th>marital_status</th>\n","      <th>number_of_dependents</th>\n","      <th>education_level</th>\n","      <th>occupation</th>\n","      <th>health_score</th>\n","      <th>location</th>\n","      <th>policy_type</th>\n","      <th>previous_claims</th>\n","      <th>vehicle_age</th>\n","      <th>credit_score</th>\n","      <th>insurance_duration</th>\n","      <th>policy_start_date</th>\n","      <th>customer_feedback</th>\n","      <th>smoking_status</th>\n","      <th>exercise_frequency</th>\n","      <th>property_type</th>\n","      <th>premium_amount</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19.0</td>\n","      <td>Female</td>\n","      <td>10049.0</td>\n","      <td>Married</td>\n","      <td>1.0</td>\n","      <td>Bachelor's</td>\n","      <td>Self-Employed</td>\n","      <td>22.598761</td>\n","      <td>Urban</td>\n","      <td>Premium</td>\n","      <td>2.0</td>\n","      <td>17.0</td>\n","      <td>372.0</td>\n","      <td>5.0</td>\n","      <td>2023-12-23 15:21:39.134960</td>\n","      <td>Poor</td>\n","      <td>No</td>\n","      <td>Weekly</td>\n","      <td>House</td>\n","      <td>2869.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39.0</td>\n","      <td>Female</td>\n","      <td>31678.0</td>\n","      <td>Divorced</td>\n","      <td>3.0</td>\n","      <td>Master's</td>\n","      <td>NaN</td>\n","      <td>15.569731</td>\n","      <td>Rural</td>\n","      <td>Comprehensive</td>\n","      <td>1.0</td>\n","      <td>12.0</td>\n","      <td>694.0</td>\n","      <td>2.0</td>\n","      <td>2023-06-12 15:21:39.111551</td>\n","      <td>Average</td>\n","      <td>Yes</td>\n","      <td>Monthly</td>\n","      <td>House</td>\n","      <td>1483.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23.0</td>\n","      <td>Male</td>\n","      <td>25602.0</td>\n","      <td>Divorced</td>\n","      <td>3.0</td>\n","      <td>High School</td>\n","      <td>Self-Employed</td>\n","      <td>47.177549</td>\n","      <td>Suburban</td>\n","      <td>Premium</td>\n","      <td>1.0</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>2023-09-30 15:21:39.221386</td>\n","      <td>Good</td>\n","      <td>Yes</td>\n","      <td>Weekly</td>\n","      <td>House</td>\n","      <td>567.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21.0</td>\n","      <td>Male</td>\n","      <td>141855.0</td>\n","      <td>Married</td>\n","      <td>2.0</td>\n","      <td>Bachelor's</td>\n","      <td>NaN</td>\n","      <td>10.938144</td>\n","      <td>Rural</td>\n","      <td>Basic</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>367.0</td>\n","      <td>1.0</td>\n","      <td>2024-06-12 15:21:39.226954</td>\n","      <td>Poor</td>\n","      <td>Yes</td>\n","      <td>Daily</td>\n","      <td>Apartment</td>\n","      <td>765.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>21.0</td>\n","      <td>Male</td>\n","      <td>39651.0</td>\n","      <td>Single</td>\n","      <td>1.0</td>\n","      <td>Bachelor's</td>\n","      <td>Self-Employed</td>\n","      <td>20.376094</td>\n","      <td>Rural</td>\n","      <td>Premium</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>598.0</td>\n","      <td>4.0</td>\n","      <td>2021-12-01 15:21:39.252145</td>\n","      <td>Poor</td>\n","      <td>Yes</td>\n","      <td>Weekly</td>\n","      <td>House</td>\n","      <td>2022.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1199995</th>\n","      <td>36.0</td>\n","      <td>Female</td>\n","      <td>27316.0</td>\n","      <td>Married</td>\n","      <td>0.0</td>\n","      <td>Master's</td>\n","      <td>Unemployed</td>\n","      <td>13.772907</td>\n","      <td>Urban</td>\n","      <td>Premium</td>\n","      <td>NaN</td>\n","      <td>5.0</td>\n","      <td>372.0</td>\n","      <td>3.0</td>\n","      <td>2023-05-03 15:21:39.257696</td>\n","      <td>Poor</td>\n","      <td>No</td>\n","      <td>Daily</td>\n","      <td>Apartment</td>\n","      <td>1303.0</td>\n","    </tr>\n","    <tr>\n","      <th>1199996</th>\n","      <td>54.0</td>\n","      <td>Male</td>\n","      <td>35786.0</td>\n","      <td>Divorced</td>\n","      <td>NaN</td>\n","      <td>Master's</td>\n","      <td>Self-Employed</td>\n","      <td>11.483482</td>\n","      <td>Rural</td>\n","      <td>Comprehensive</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>597.0</td>\n","      <td>4.0</td>\n","      <td>2022-09-10 15:21:39.134960</td>\n","      <td>Poor</td>\n","      <td>No</td>\n","      <td>Weekly</td>\n","      <td>Apartment</td>\n","      <td>821.0</td>\n","    </tr>\n","    <tr>\n","      <th>1199997</th>\n","      <td>19.0</td>\n","      <td>Male</td>\n","      <td>51884.0</td>\n","      <td>Divorced</td>\n","      <td>0.0</td>\n","      <td>Master's</td>\n","      <td>NaN</td>\n","      <td>14.724469</td>\n","      <td>Suburban</td>\n","      <td>Basic</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>NaN</td>\n","      <td>6.0</td>\n","      <td>2021-05-25 15:21:39.106582</td>\n","      <td>Good</td>\n","      <td>No</td>\n","      <td>Monthly</td>\n","      <td>Condo</td>\n","      <td>371.0</td>\n","    </tr>\n","    <tr>\n","      <th>1199998</th>\n","      <td>55.0</td>\n","      <td>Male</td>\n","      <td>NaN</td>\n","      <td>Single</td>\n","      <td>1.0</td>\n","      <td>PhD</td>\n","      <td>NaN</td>\n","      <td>18.547381</td>\n","      <td>Suburban</td>\n","      <td>Premium</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>407.0</td>\n","      <td>4.0</td>\n","      <td>2021-09-19 15:21:39.190215</td>\n","      <td>Poor</td>\n","      <td>No</td>\n","      <td>Daily</td>\n","      <td>Apartment</td>\n","      <td>596.0</td>\n","    </tr>\n","    <tr>\n","      <th>1199999</th>\n","      <td>21.0</td>\n","      <td>Female</td>\n","      <td>NaN</td>\n","      <td>Divorced</td>\n","      <td>0.0</td>\n","      <td>PhD</td>\n","      <td>NaN</td>\n","      <td>10.125323</td>\n","      <td>Rural</td>\n","      <td>Premium</td>\n","      <td>0.0</td>\n","      <td>18.0</td>\n","      <td>502.0</td>\n","      <td>6.0</td>\n","      <td>2020-08-26 15:21:39.155231</td>\n","      <td>Good</td>\n","      <td>Yes</td>\n","      <td>Monthly</td>\n","      <td>House</td>\n","      <td>2480.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1200000 rows × 20 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-761923df-b91a-46cf-aebd-46c8681f5799')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-761923df-b91a-46cf-aebd-46c8681f5799 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-761923df-b91a-46cf-aebd-46c8681f5799');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0f46fa5e-186a-44c2-b594-0c74e597a216\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f46fa5e-186a-44c2-b594-0c74e597a216')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0f46fa5e-186a-44c2-b594-0c74e597a216 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_8c35f613-ad68-4566-a019-d543d895be7a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8c35f613-ad68-4566-a019-d543d895be7a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train"}},"metadata":{},"execution_count":17}],"source":["train.set_index('id', inplace=True)\n","test.set_index('id', inplace=True)\n","\n","# Renaming columns for consistency\n","train.columns = train.columns.str.lower()\n","test.columns = test.columns.str.lower()\n","original.columns = original.columns.str.lower()\n","train.columns = [col.replace(\" \", \"_\") for col in train.columns]\n","test.columns = [col.replace(\" \", \"_\") for col in test.columns]\n","original.columns = [col.replace(\" \", \"_\") for col in original.columns]\n","original  = original[train.columns]\n","original = original.dropna(subset=['premium_amount'])\n","\n","train"]},{"cell_type":"markdown","id":"b1bc1bef","metadata":{"papermill":{"duration":0.003714,"end_time":"2024-12-30T13:56:37.930227","exception":false,"start_time":"2024-12-30T13:56:37.926513","status":"completed"},"tags":[],"id":"b1bc1bef"},"source":["# **Feature Engineering**\n","\n","Lets do some feature engineering with help from `claude.ai`\n"]},{"cell_type":"code","execution_count":18,"id":"01062b15","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:37.938930Z","iopub.status.busy":"2024-12-30T13:56:37.938647Z","iopub.status.idle":"2024-12-30T13:56:37.946948Z","shell.execute_reply":"2024-12-30T13:56:37.946106Z"},"papermill":{"duration":0.014074,"end_time":"2024-12-30T13:56:37.948196","exception":false,"start_time":"2024-12-30T13:56:37.934122","status":"completed"},"tags":[],"id":"01062b15","executionInfo":{"status":"ok","timestamp":1735604744883,"user_tz":180,"elapsed":2,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["def create_date_features(df):\n","    # Basic date features\n","    df['policy_start'] = pd.to_datetime(df['policy_start_date'])\n","    df['year'] = df['policy_start'].dt.year\n","    df['month'] = df['policy_start'].dt.month\n","    df['day'] = df['policy_start'].dt.day\n","    df['week_of_year'] = df['policy_start'].dt.isocalendar().week.astype('int')\n","    df['day_of_week'] = df['policy_start'].dt.day_name()\n","    df['month_name'] = df['policy_start'].dt.month_name()\n","    df['quarter'] = df['policy_start'].dt.quarter\n","\n","    # Cyclical encoding\n","    for col, max_val in [('year', 1), ('month', 12), ('day', 31)]:\n","        df[f'{col}_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n","        df[f'{col}_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n","\n","    # Binary flags\n","    df['is_weekend'] = df['policy_start'].dt.dayofweek.isin([5,6]).astype(int)\n","    df['is_month_end'] = df['policy_start'].dt.is_month_end.astype(int)\n","    df['is_month_start'] = df['policy_start'].dt.is_month_start.astype(int)\n","    df['is_quarter_end'] = df['policy_start'].dt.is_quarter_end.astype(int)\n","    df['is_quarter_start'] = df['policy_start'].dt.is_quarter_start.astype(int)\n","\n","    # Time-based calculations\n","    df['policy_age_days'] = (df['policy_start'].max() - df['policy_start']).dt.days\n","    df['week_of_month'] = df['day'].apply(lambda x: (x-1)//7 + 1)\n","    df['days_in_month'] = df['policy_start'].dt.days_in_month\n","    df['days_remaining_in_month'] = df['days_in_month'] - df['day']\n","\n","    # Seasonal mapping\n","    season_map = {12:'winter', 1:'winter', 2:'winter',\n","                  3:'spring', 4:'spring', 5:'spring',\n","                  6:'summer', 7:'summer', 8:'summer',\n","                  9:'fall', 10:'fall', 11:'fall'}\n","    df['season'] = df['month'].map(season_map)\n","\n","    return df"]},{"cell_type":"code","execution_count":19,"id":"5c3cbfcd","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:37.956577Z","iopub.status.busy":"2024-12-30T13:56:37.956355Z","iopub.status.idle":"2024-12-30T13:56:37.968269Z","shell.execute_reply":"2024-12-30T13:56:37.967624Z"},"papermill":{"duration":0.017562,"end_time":"2024-12-30T13:56:37.969468","exception":false,"start_time":"2024-12-30T13:56:37.951906","status":"completed"},"tags":[],"id":"5c3cbfcd","executionInfo":{"status":"ok","timestamp":1735604744883,"user_tz":180,"elapsed":1,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["def create_advanced_features(df, is_training=True):\n","    \"\"\"\n","    Create advanced features for insurance premium prediction with proper scaling\n","    \"\"\"\n","    df = df.copy()\n","\n","    # Store scaling factors during training\n","    if is_training:\n","        global scale_params\n","        scale_params = {\n","            'health_score_mean': df['health_score'].mean(),\n","            'health_score_std': df['health_score'].std(),\n","            'credit_score_mean': df['credit_score'].mean(),\n","            'credit_score_std': df['credit_score'].std(),\n","            'customer_feedback_map': {\n","                'Poor': 0.0,    # Higher risk\n","                'Average': 0.5, # Medium risk\n","                'Good': 1.0     # Lower risk\n","            },\n","            'exercise_frequency_map': {\n","                'Rarely': 0.0,   # Highest risk\n","                'Monthly': 0.33, # High risk\n","                'Weekly': 0.66,  # Low risk\n","                'Daily': 1.0     # Lowest risk\n","            },\n","            'smoking_map': {\n","                'Yes': 1.0,  # Higher risk\n","                'No': 0.0    # Lower risk\n","            },\n","            'marital_risk_map': {\n","                'Single': 1.0,    # Base risk\n","                'Married': 0.8,   # Lower risk (shared responsibility)\n","                'Divorced': 1.2   # Higher risk (potentially more financial stress)\n","            },\n","            'property_risk_map': {\n","                'Apartment': 1.0,  # Base risk\n","                'House': 1.5,     # Higher risk (more value/larger space)\n","                'Condo': 1.2      # Medium risk\n","            }\n","        }\n","\n","    # 1. Date-based features\n","    df = create_date_features(df)\n","\n","    # 2. Income-based features with proper scaling\n","    df['income_per_dependent'] = df['annual_income'] / (df['number_of_dependents'] + 1)\n","    df['income_bracket'] = pd.qcut(df['annual_income'], q=5,\n","                                 labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n","\n","    # 3. Risk Score Combinations with standardization\n","    # Standardize health and credit scores\n","    df['health_score_std'] = (df['health_score'] - scale_params['health_score_mean']) / scale_params['health_score_std']\n","    df['credit_score_std'] = (df['credit_score'] - scale_params['credit_score_mean']) / scale_params['credit_score_std']\n","\n","    # Combined risk score (now both features are on same scale)\n","    df['total_risk_score'] = df['health_score_std'] + df['credit_score_std']\n","\n","    # Claims ratio with insurance duration\n","    df['claims_to_duration_ratio'] = df['previous_claims'] / (df['insurance_duration'] + 1)\n","\n","    # 4. Age-related interactions\n","    df['vehicle_to_driver_age_ratio'] = df['vehicle_age'] / df['age']\n","    df['is_young_driver'] = (df['age'] < 25).astype(int)\n","    df['is_senior_driver'] = (df['age'] > 65).astype(int)\n","\n","    # 5. Lifestyle Score (normalized to 0-1 range)\n","    df['exercise_score'] = df['exercise_frequency'].map(scale_params['exercise_frequency_map'])\n","    df['smoking_risk'] = df['smoking_status'].map(scale_params['smoking_map'])\n","    df['lifestyle_score'] = (\n","        df['exercise_score'] * 0.4 +    # Exercise has significant impact\n","        (1 - df['smoking_risk']) * 0.4 + # Non-smoking is positive\n","        (df['health_score_std'] > 0) * 0.2  # Above average health is positive\n","    )\n","\n","    # 6. Location-based features\n","    if is_training:\n","        scale_params['location_risk_map'] = df.groupby('location')['previous_claims'].mean()\n","        scale_params['location_credit_map'] = df.groupby('location')['credit_score'].mean()\n","\n","    df['location_risk'] = df['location'].map(scale_params['location_risk_map'])\n","    df['location_avg_credit'] = df['location'].map(scale_params['location_credit_map'])\n","\n","    # 7. Complex Interaction Features\n","    df['customer_feedback_score'] = df['customer_feedback'].map(scale_params['customer_feedback_map'])\n","\n","    # Weighted responsibility score (all components now 0-1 scaled)\n","    df['responsibility_score'] = (\n","        df['credit_score_std'].clip(-3, 3) * 0.4 +  # Limit outlier effect\n","        df['customer_feedback_score'] * 0.3 +\n","        (1 - df['claims_to_duration_ratio'].clip(0, 1)) * 0.3  # Lower claims is better\n","    )\n","\n","    # 8. Family and Property Risk\n","    df['marital_risk'] = df['marital_status'].map(scale_params['marital_risk_map'])\n","    df['property_risk'] = df['property_type'].map(scale_params['property_risk_map'])\n","\n","    # Combined risk factors\n","    df['family_risk_factor'] = df['marital_risk'] * (df['number_of_dependents'] + 1)\n","    df['asset_risk'] = (\n","        df['property_risk'] * 0.6 +\n","        (df['vehicle_age'] / df['vehicle_age'].max()) * 0.4  # Normalized vehicle age\n","    )\n","\n","    # 9. Customer Segment Features\n","    df['premium_segment'] = 'Standard'\n","    mask_premium = (\n","        (df['credit_score_std'] > 1) &  # Above 1 std in credit\n","        (df['previous_claims'] == 0) &   # No claims\n","        (df['health_score_std'] > 1)     # Above 1 std in health\n","    )\n","    mask_high_risk = (\n","        (df['credit_score_std'] < -1) |  # Below 1 std in credit\n","        (df['previous_claims'] > 3)       # Multiple claims\n","    )\n","\n","    df.loc[mask_premium, 'premium_segment'] = 'Premium'\n","    df.loc[mask_high_risk, 'premium_segment'] = 'High Risk'\n","\n","    # 10. Additional Ratio Features\n","    df['claims_per_year'] = df['previous_claims'] / (df['insurance_duration'] + 1)\n","    df['dependent_income_ratio'] = df['number_of_dependents'] / df['annual_income']\n","\n","    # Drop intermediate columns\n","    intermediate_cols = ['health_score_std', 'credit_score_std', 'exercise_score',\n","                        'smoking_risk', 'customer_feedback_score', 'marital_risk',\n","                        'property_risk']\n","    df = df.drop(columns=[col for col in intermediate_cols if col in df.columns])\n","\n","    return df"]},{"cell_type":"code","execution_count":20,"id":"56c64bc5","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:37.977965Z","iopub.status.busy":"2024-12-30T13:56:37.977735Z","iopub.status.idle":"2024-12-30T13:56:44.441034Z","shell.execute_reply":"2024-12-30T13:56:44.440069Z"},"papermill":{"duration":6.46896,"end_time":"2024-12-30T13:56:44.442373","exception":false,"start_time":"2024-12-30T13:56:37.973413","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"56c64bc5","executionInfo":{"status":"ok","timestamp":1735604751714,"user_tz":180,"elapsed":6027,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}},"outputId":"fe1e38c9-f538-44c6-c90a-76cf92845cc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data transformation successful!\n","Test data transformation successful!\n"]}],"source":["try:\n","    # Transform training data\n","    train_transformed = create_advanced_features(train, is_training=True)\n","    print(\"Training data transformation successful!\")\n","\n","    # Transform test data\n","    test_transformed = create_advanced_features(test, is_training=False)\n","    print(\"Test data transformation successful!\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {str(e)}\")\n","    print(\"Please check your data types and column names.\")"]},{"cell_type":"code","execution_count":21,"id":"f7bbec56","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:44.451389Z","iopub.status.busy":"2024-12-30T13:56:44.451118Z","iopub.status.idle":"2024-12-30T13:56:44.818886Z","shell.execute_reply":"2024-12-30T13:56:44.818207Z"},"papermill":{"duration":0.37397,"end_time":"2024-12-30T13:56:44.820646","exception":false,"start_time":"2024-12-30T13:56:44.446676","status":"completed"},"tags":[],"id":"f7bbec56","executionInfo":{"status":"ok","timestamp":1735604752024,"user_tz":180,"elapsed":314,"user":{"displayName":"Fabián Alberto Reyes Madrid","userId":"11772448517145602220"}}},"outputs":[],"source":["# Lets do one more transformation + oofs for stacking\n","train_transformed['premium_amount_log'] = np.log1p(train_transformed['premium_amount'])\n","train_transformed.drop(columns=\"premium_amount\", inplace=True)\n","train_transformed[['4log_WeightedEnsemble_L4', '12nonlog_WeightedEnsemble_L3']] = train_oofs.set_index(\"id\")[['4log_WeightedEnsemble_L4', '12nonlog_WeightedEnsemble_L3']]\n","test_transformed[['4log_WeightedEnsemble_L4', '12nonlog_WeightedEnsemble_L3']] = test_oofs.set_index(\"id\")[['4log_WeightedEnsemble_L4', '12nonlog_WeightedEnsemble_L3']]"]},{"cell_type":"markdown","id":"11805ea1","metadata":{"papermill":{"duration":0.004064,"end_time":"2024-12-30T13:56:44.829437","exception":false,"start_time":"2024-12-30T13:56:44.825373","status":"completed"},"tags":[],"id":"11805ea1"},"source":["# **Autogluon training**"]},{"cell_type":"code","execution_count":null,"id":"bd6be70d","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:44.837895Z","iopub.status.busy":"2024-12-30T13:56:44.837638Z","iopub.status.idle":"2024-12-30T13:56:44.840691Z","shell.execute_reply":"2024-12-30T13:56:44.839916Z"},"papermill":{"duration":0.008663,"end_time":"2024-12-30T13:56:44.841933","exception":false,"start_time":"2024-12-30T13:56:44.833270","status":"completed"},"tags":[],"id":"bd6be70d"},"outputs":[],"source":["# Create the AutoGluon scorer using sklearn's implementation\n","#rmsle_scorer = make_scorer(\n","#    name='rmsle',\n","#    score_func=sklearn.metrics.root_mean_squared_log_error,\n","#    optimum=0,\n","#    greater_is_better=False,\n","#    needs_pred=True\n","#)"]},{"cell_type":"code","execution_count":null,"id":"74d8001a","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:56:44.850441Z","iopub.status.busy":"2024-12-30T13:56:44.850202Z","iopub.status.idle":"2024-12-30T21:59:36.597435Z","shell.execute_reply":"2024-12-30T21:59:36.596481Z"},"papermill":{"duration":28971.753023,"end_time":"2024-12-30T21:59:36.598860","exception":false,"start_time":"2024-12-30T13:56:44.845837","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"74d8001a","outputId":"b0106ff1-bd6f-485f-fa2c-11683e0bbdb2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.2\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          8\n","Memory Avail:       46.03 GB / 50.99 GB (90.3%)\n","Disk Space Avail:   201.58 GB / 235.68 GB (85.5%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=2\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 10800s of the 43200s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-12-31 00:27:23,913\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/kaggle/working/Autogluon/202412_ps4s12_12hr_training_oofs/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=3262)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m Beginning AutoGluon training ... Time limit = 10797s\n","\u001b[36m(_dystack pid=3262)\u001b[0m AutoGluon will save models to \"/kaggle/working/Autogluon/202412_ps4s12_12hr_training_oofs/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=3262)\u001b[0m Train Data Rows:    1066666\n","\u001b[36m(_dystack pid=3262)\u001b[0m Train Data Columns: 61\n","\u001b[36m(_dystack pid=3262)\u001b[0m Label Column:       premium_amount_log\n","\u001b[36m(_dystack pid=3262)\u001b[0m Problem Type:       regression\n","\u001b[36m(_dystack pid=3262)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tAvailable Memory:                    45986.80 MB\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tTrain Data (Original)  Memory Usage: 1318.80 MB (2.9% of available memory)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tUseless Original Features (Count: 2): ['year_cos', 'is_senior_driver']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tThese features do not need to be present at inference time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tUnused Original Features (Count: 1): ['claims_per_year']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\tThese features do not need to be present at inference time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('float', []) : 1 | ['claims_per_year']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('category', [])                   :  1 | ['income_bracket']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('datetime', [])                   :  1 | ['policy_start']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('float', [])                      : 26 | ['age', 'annual_income', 'number_of_dependents', 'health_score', 'previous_claims', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('int', [])                        : 15 | ['year', 'month', 'day', 'week_of_year', 'quarter', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('object', [])                     : 14 | ['gender', 'marital_status', 'education_level', 'occupation', 'location', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('object', ['datetime_as_object']) :  1 | ['policy_start_date']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('category', [])             : 13 | ['marital_status', 'education_level', 'occupation', 'location', 'policy_type', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('float', [])                : 26 | ['age', 'annual_income', 'number_of_dependents', 'health_score', 'previous_claims', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('int', [])                  :  9 | ['year', 'month', 'day', 'week_of_year', 'quarter', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('int', ['bool'])            :  8 | ['gender', 'smoking_status', 'is_weekend', 'is_month_end', 'is_month_start', ...]\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t('int', ['datetime_as_int']) :  2 | ['policy_start_date', 'policy_start_date.dayofweek']\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t15.8s = Fit runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t58 features in original data used to generate 58 features in processed data.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tTrain Data (Processed) Memory Usage: 298.06 MB (0.6% of available memory)\n","\u001b[36m(_dystack pid=3262)\u001b[0m Data preprocessing and feature engineering runtime = 17.81s ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=3262)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=3262)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=3262)\u001b[0m {\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=3262)\u001b[0m }\n","\u001b[36m(_dystack pid=3262)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m Excluded models: ['KNN', 'RF', 'FASTAI'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting 75 L1 models, fit_strategy=\"sequential\" ...\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 7184.22s of the 10779.01s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.37%)\n","\u001b[36m(_ray_fit pid=4299)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4299)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4627)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4627)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4887)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4887)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5206)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5206)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5472)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5472)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5699)\u001b[0m \tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5699)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6065)\u001b[0m \tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6065)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6275)\u001b[0m \tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6275)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6619)\u001b[0m \tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6619)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6973)\u001b[0m \tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6973)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.045\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t590.06s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t29.79s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 6585.49s of the 10180.28s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.41%)\n","\u001b[36m(_ray_fit pid=7514)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7514)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7670)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7670)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7811)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7811)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7957)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7957)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8101)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8101)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8250)\u001b[0m \tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8250)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8393)\u001b[0m \tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8393)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8530)\u001b[0m \tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8530)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8680)\u001b[0m \tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8680)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=8831)\u001b[0m \tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8831)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.0445\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t244.86s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t6.55s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 6337.08s of the 9931.88s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.44%)\n","\u001b[36m(_ray_fit pid=9226)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=9226)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=9471)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=9471)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=9690)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=9690)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=9908)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=9908)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10122)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=10122)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10344)\u001b[0m \tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=10344)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10556)\u001b[0m \tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=10556)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=10791)\u001b[0m \tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=10791)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=11002)\u001b[0m \tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=11002)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=11220)\u001b[0m \tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=11220)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.0446\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t352.94s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t1.12s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 5981.15s of the 9575.94s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n","\u001b[36m(_dystack pid=3262)\u001b[0m   warnings.warn(\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.0462\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t616.25s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t54.56s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 5308.73s of the 8903.53s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=5.88%)\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The OneHotMergeRaresHandleUnknownEncoder or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n","\u001b[36m(_ray_fit pid=14617)\u001b[0m   warnings.warn(\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14617, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 118, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self.preprocess(X, is_train=True, max_category_levels=max_category_levels)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 426, in preprocess\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self._preprocess(X, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 78, in _preprocess\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self._ohe_generator.transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 155, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X_list.append(self.ohe_encs.transform(X[self.cat_cols]))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Detailed Traceback:\n","\u001b[36m(_dystack pid=3262)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._fit_folds(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise processed_exception\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fn(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n","\u001b[36m(_dystack pid=3262)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise value.as_instanceof_cause()\n","\u001b[36m(_dystack pid=3262)\u001b[0m ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14617, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 118, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self.preprocess(X, is_train=True, max_category_levels=max_category_levels)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 426, in preprocess\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self._preprocess(X, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 78, in _preprocess\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X = self._ohe_generator.transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 155, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     X_list.append(self.ohe_encs.transform(X[self.cat_cols]))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5301.47s of the 8896.27s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.25%)\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The OneHotMergeRaresHandleUnknownEncoder or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n","\u001b[36m(_ray_fit pid=14935)\u001b[0m   warnings.warn(\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14935, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n","\u001b[36m(_dystack pid=3262)\u001b[0m     dataset = self._process_train_data(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n","\u001b[36m(_dystack pid=3262)\u001b[0m     df = self.processor.fit_transform(df)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 1000, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     result = self._call_func_on_transformers(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 909, in _call_func_on_transformers\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super().__call__(iterable_with_config)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return output if self.return_generator else list(output)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.function(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 728, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return last_step.fit_transform(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 918, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Detailed Traceback:\n","\u001b[36m(_dystack pid=3262)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._fit_folds(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise processed_exception\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fn(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n","\u001b[36m(_dystack pid=3262)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise value.as_instanceof_cause()\n","\u001b[36m(_dystack pid=3262)\u001b[0m ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14935, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n","\u001b[36m(_dystack pid=3262)\u001b[0m     dataset = self._process_train_data(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n","\u001b[36m(_dystack pid=3262)\u001b[0m     df = self.processor.fit_transform(df)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 1000, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     result = self._call_func_on_transformers(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 909, in _call_func_on_transformers\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super().__call__(iterable_with_config)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return output if self.return_generator else list(output)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.function(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 728, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return last_step.fit_transform(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 918, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5285.05s of the 8879.85s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.61%)\n","\u001b[36m(_ray_fit pid=15302)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=15302)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=15510)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=15510)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=15732)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=15732)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=15940)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=15940)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=16129)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=16129)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=16343)\u001b[0m \tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=16343)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=16537)\u001b[0m \tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=16537)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=16738)\u001b[0m \tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=16738)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=16947)\u001b[0m \tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=16947)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=17137)\u001b[0m \tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=17137)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.0446\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t362.32s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t11.53s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4918.53s of the 8513.33s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.51%)\n","\u001b[36m(_ray_fit pid=17591)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=17591)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=17719)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=17719)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=17848)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=17848)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=17978)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=17978)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18110)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18110)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18237)\u001b[0m \tTraining S2F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18237)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18359)\u001b[0m \tTraining S2F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18359)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18486)\u001b[0m \tTraining S2F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18486)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18612)\u001b[0m \tTraining S2F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18612)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=18740)\u001b[0m \tTraining S2F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=18740)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t-1.0446\t = Validation score   (-root_mean_squared_error)\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t124.6s\t = Training   runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t0.87s\t = Validation runtime\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4790.77s of the 8385.57s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.28%)\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m /usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The OneHotMergeRaresHandleUnknownEncoder or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n","\u001b[36m(_ray_fit pid=19122)\u001b[0m   warnings.warn(\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19122, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n","\u001b[36m(_dystack pid=3262)\u001b[0m     dataset = self._process_train_data(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n","\u001b[36m(_dystack pid=3262)\u001b[0m     df = self.processor.fit_transform(df)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 1000, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     result = self._call_func_on_transformers(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 909, in _call_func_on_transformers\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super().__call__(iterable_with_config)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return output if self.return_generator else list(output)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.function(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 728, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return last_step.fit_transform(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 918, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Detailed Traceback:\n","\u001b[36m(_dystack pid=3262)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n","\u001b[36m(_dystack pid=3262)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._fit_folds(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n","\u001b[36m(_dystack pid=3262)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise processed_exception\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fn(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n","\u001b[36m(_dystack pid=3262)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n","\u001b[36m(_dystack pid=3262)\u001b[0m     raise value.as_instanceof_cause()\n","\u001b[36m(_dystack pid=3262)\u001b[0m ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19122, ip=172.28.0.12)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     out = self._fit(**kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 201, in _fit\n","\u001b[36m(_dystack pid=3262)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 669, in _generate_dataset\n","\u001b[36m(_dystack pid=3262)\u001b[0m     dataset = self._process_train_data(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 744, in _process_train_data\n","\u001b[36m(_dystack pid=3262)\u001b[0m     df = self.processor.fit_transform(df)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 1000, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     result = self._call_func_on_transformers(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 909, in _call_func_on_transformers\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return Parallel(n_jobs=self.n_jobs)(jobs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return super().__call__(iterable_with_config)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return output if self.return_generator else list(output)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = func(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.function(*args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n","\u001b[36m(_dystack pid=3262)\u001b[0m     res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return fit_method(estimator, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 728, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return last_step.fit_transform(\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 918, in fit_transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     return self.fit(X, **fit_params).transform(X)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n","\u001b[36m(_dystack pid=3262)\u001b[0m     data_to_wrap = f(self, X, *args, **kwargs)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/utils/categorical_encoders.py\", line 483, in transform\n","\u001b[36m(_dystack pid=3262)\u001b[0m     check_is_fitted(self, \"categories_\")\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1751, in check_is_fitted\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = get_tags(estimator)\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\", line 405, in get_tags\n","\u001b[36m(_dystack pid=3262)\u001b[0m     sklearn_tags_provider[klass] = klass.__sklearn_tags__(estimator)  # type: ignore[attr-defined]\n","\u001b[36m(_dystack pid=3262)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 859, in __sklearn_tags__\n","\u001b[36m(_dystack pid=3262)\u001b[0m     tags = super().__sklearn_tags__()\n","\u001b[36m(_dystack pid=3262)\u001b[0m AttributeError: 'super' object has no attribute '__sklearn_tags__'\n","\u001b[36m(_dystack pid=3262)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 4775.83s of the 8370.62s of remaining time.\n","\u001b[36m(_dystack pid=3262)\u001b[0m \tFitting 10 child models (S1F1 - S2F5) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.50%)\n","\u001b[36m(_ray_fit pid=19477)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=19477)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=19943)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=19943)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=20422)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=20422)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"]}],"source":["# Setting up\n","eval_metric = 'rmse'\n","label = 'premium_amount_log'\n","problem_type='regression'\n","excluded_model_types = ['KNN', 'RF', 'FASTAI']\n","hours = 12\n","\n","# Initialize the TabularPredictor\n","predictor = TabularPredictor(label=label,\n","                             problem_type=problem_type,\n","                             eval_metric=eval_metric,\n","                             path = \"/kaggle/working/Autogluon/202412_ps4s12_12hr_training_oofs\")\n","\n","# Fit the model\n","predictor.fit(train_data=train_transformed,\n","              time_limit=3600*hours,\n","              presets=\"best_quality\",\n","              excluded_model_types=excluded_model_types,\n","              num_bag_folds=5,\n","              num_bag_sets=2,\n","              ag_args_fit={'num_gpus': 1}\n",")"]},{"cell_type":"markdown","id":"4e50e9e9","metadata":{"papermill":{"duration":0.031444,"end_time":"2024-12-30T21:59:36.663219","exception":false,"start_time":"2024-12-30T21:59:36.631775","status":"completed"},"tags":[],"id":"4e50e9e9"},"source":["# **Leaderboard and Submission**"]},{"cell_type":"code","execution_count":null,"id":"bb6ad2da","metadata":{"execution":{"iopub.execute_input":"2024-12-30T21:59:36.729398Z","iopub.status.busy":"2024-12-30T21:59:36.728362Z","iopub.status.idle":"2024-12-30T21:59:36.750907Z","shell.execute_reply":"2024-12-30T21:59:36.750250Z"},"papermill":{"duration":0.057582,"end_time":"2024-12-30T21:59:36.752543","exception":false,"start_time":"2024-12-30T21:59:36.694961","status":"completed"},"tags":[],"id":"bb6ad2da","outputId":"c14ac607-9863-491f-96f4-a32d98da46f8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-1.044502</td>\n","      <td>root_mean_squared_error</td>\n","      <td>142.252649</td>\n","      <td>2697.468294</td>\n","      <td>0.015908</td>\n","      <td>3.100807</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LightGBM_BAG_L1</td>\n","      <td>-1.044563</td>\n","      <td>root_mean_squared_error</td>\n","      <td>8.727121</td>\n","      <td>258.000325</td>\n","      <td>8.727121</td>\n","      <td>258.000325</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LightGBM_r131_BAG_L1</td>\n","      <td>-1.044581</td>\n","      <td>root_mean_squared_error</td>\n","      <td>68.917408</td>\n","      <td>831.180480</td>\n","      <td>68.917408</td>\n","      <td>831.180480</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CatBoost_r50_BAG_L1</td>\n","      <td>-1.044589</td>\n","      <td>root_mean_squared_error</td>\n","      <td>3.437553</td>\n","      <td>264.182947</td>\n","      <td>3.437553</td>\n","      <td>264.182947</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CatBoost_r70_BAG_L1</td>\n","      <td>-1.044595</td>\n","      <td>root_mean_squared_error</td>\n","      <td>5.083509</td>\n","      <td>276.157853</td>\n","      <td>5.083509</td>\n","      <td>276.157853</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CatBoost_r9_BAG_L1</td>\n","      <td>-1.044651</td>\n","      <td>root_mean_squared_error</td>\n","      <td>6.575855</td>\n","      <td>289.730436</td>\n","      <td>6.575855</td>\n","      <td>289.730436</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CatBoost_BAG_L1</td>\n","      <td>-1.044652</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.274065</td>\n","      <td>548.236788</td>\n","      <td>2.274065</td>\n","      <td>548.236788</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>CatBoost_r13_BAG_L1</td>\n","      <td>-1.044652</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.260915</td>\n","      <td>369.959164</td>\n","      <td>2.260915</td>\n","      <td>369.959164</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoost_r177_BAG_L1</td>\n","      <td>-1.044654</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.612325</td>\n","      <td>214.641087</td>\n","      <td>1.612325</td>\n","      <td>214.641087</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CatBoost_r69_BAG_L1</td>\n","      <td>-1.044660</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.096287</td>\n","      <td>450.950129</td>\n","      <td>2.096287</td>\n","      <td>450.950129</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LightGBMLarge_BAG_L1</td>\n","      <td>-1.044663</td>\n","      <td>root_mean_squared_error</td>\n","      <td>16.077509</td>\n","      <td>395.926899</td>\n","      <td>16.077509</td>\n","      <td>395.926899</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CatBoost_r137_BAG_L1</td>\n","      <td>-1.044675</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.177178</td>\n","      <td>388.208637</td>\n","      <td>2.177178</td>\n","      <td>388.208637</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LightGBM_r130_BAG_L1</td>\n","      <td>-1.044705</td>\n","      <td>root_mean_squared_error</td>\n","      <td>15.097635</td>\n","      <td>328.541440</td>\n","      <td>15.097635</td>\n","      <td>328.541440</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LightGBM_r161_BAG_L1</td>\n","      <td>-1.044710</td>\n","      <td>root_mean_squared_error</td>\n","      <td>105.835947</td>\n","      <td>1170.866613</td>\n","      <td>105.835947</td>\n","      <td>1170.866613</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>XGBoost_r194_BAG_L1</td>\n","      <td>-1.044711</td>\n","      <td>root_mean_squared_error</td>\n","      <td>4.793463</td>\n","      <td>263.326220</td>\n","      <td>4.793463</td>\n","      <td>263.326220</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>LightGBMXT_BAG_L1</td>\n","      <td>-1.045107</td>\n","      <td>root_mean_squared_error</td>\n","      <td>43.567207</td>\n","      <td>492.986456</td>\n","      <td>43.567207</td>\n","      <td>492.986456</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>LightGBM_r96_BAG_L1</td>\n","      <td>-1.045114</td>\n","      <td>root_mean_squared_error</td>\n","      <td>526.585319</td>\n","      <td>3146.441044</td>\n","      <td>526.585319</td>\n","      <td>3146.441044</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>LightGBM_r188_BAG_L1</td>\n","      <td>-1.045344</td>\n","      <td>root_mean_squared_error</td>\n","      <td>65.388785</td>\n","      <td>736.034792</td>\n","      <td>65.388785</td>\n","      <td>736.034792</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>LightGBM_r196_BAG_L1</td>\n","      <td>-1.045395</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1384.004349</td>\n","      <td>6819.561158</td>\n","      <td>1384.004349</td>\n","      <td>6819.561158</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>ExtraTrees_r172_BAG_L1</td>\n","      <td>-1.045870</td>\n","      <td>root_mean_squared_error</td>\n","      <td>56.136590</td>\n","      <td>1377.642815</td>\n","      <td>56.136590</td>\n","      <td>1377.642815</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>ExtraTreesMSE_BAG_L1</td>\n","      <td>-1.046131</td>\n","      <td>root_mean_squared_error</td>\n","      <td>54.671981</td>\n","      <td>1339.701798</td>\n","      <td>54.671981</td>\n","      <td>1339.701798</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>ExtraTrees_r42_BAG_L1</td>\n","      <td>-1.046138</td>\n","      <td>root_mean_squared_error</td>\n","      <td>56.361198</td>\n","      <td>1077.677516</td>\n","      <td>56.361198</td>\n","      <td>1077.677516</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     model  score_val              eval_metric  pred_time_val  \\\n","0      WeightedEnsemble_L2  -1.044502  root_mean_squared_error     142.252649   \n","1          LightGBM_BAG_L1  -1.044563  root_mean_squared_error       8.727121   \n","2     LightGBM_r131_BAG_L1  -1.044581  root_mean_squared_error      68.917408   \n","3      CatBoost_r50_BAG_L1  -1.044589  root_mean_squared_error       3.437553   \n","4      CatBoost_r70_BAG_L1  -1.044595  root_mean_squared_error       5.083509   \n","5       CatBoost_r9_BAG_L1  -1.044651  root_mean_squared_error       6.575855   \n","6          CatBoost_BAG_L1  -1.044652  root_mean_squared_error       2.274065   \n","7      CatBoost_r13_BAG_L1  -1.044652  root_mean_squared_error       2.260915   \n","8     CatBoost_r177_BAG_L1  -1.044654  root_mean_squared_error       1.612325   \n","9      CatBoost_r69_BAG_L1  -1.044660  root_mean_squared_error       2.096287   \n","10    LightGBMLarge_BAG_L1  -1.044663  root_mean_squared_error      16.077509   \n","11    CatBoost_r137_BAG_L1  -1.044675  root_mean_squared_error       2.177178   \n","12    LightGBM_r130_BAG_L1  -1.044705  root_mean_squared_error      15.097635   \n","13    LightGBM_r161_BAG_L1  -1.044710  root_mean_squared_error     105.835947   \n","14     XGBoost_r194_BAG_L1  -1.044711  root_mean_squared_error       4.793463   \n","15       LightGBMXT_BAG_L1  -1.045107  root_mean_squared_error      43.567207   \n","16     LightGBM_r96_BAG_L1  -1.045114  root_mean_squared_error     526.585319   \n","17    LightGBM_r188_BAG_L1  -1.045344  root_mean_squared_error      65.388785   \n","18    LightGBM_r196_BAG_L1  -1.045395  root_mean_squared_error    1384.004349   \n","19  ExtraTrees_r172_BAG_L1  -1.045870  root_mean_squared_error      56.136590   \n","20    ExtraTreesMSE_BAG_L1  -1.046131  root_mean_squared_error      54.671981   \n","21   ExtraTrees_r42_BAG_L1  -1.046138  root_mean_squared_error      56.361198   \n","\n","       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n","0   2697.468294                0.015908           3.100807            2   \n","1    258.000325                8.727121         258.000325            1   \n","2    831.180480               68.917408         831.180480            1   \n","3    264.182947                3.437553         264.182947            1   \n","4    276.157853                5.083509         276.157853            1   \n","5    289.730436                6.575855         289.730436            1   \n","6    548.236788                2.274065         548.236788            1   \n","7    369.959164                2.260915         369.959164            1   \n","8    214.641087                1.612325         214.641087            1   \n","9    450.950129                2.096287         450.950129            1   \n","10   395.926899               16.077509         395.926899            1   \n","11   388.208637                2.177178         388.208637            1   \n","12   328.541440               15.097635         328.541440            1   \n","13  1170.866613              105.835947        1170.866613            1   \n","14   263.326220                4.793463         263.326220            1   \n","15   492.986456               43.567207         492.986456            1   \n","16  3146.441044              526.585319        3146.441044            1   \n","17   736.034792               65.388785         736.034792            1   \n","18  6819.561158             1384.004349        6819.561158            1   \n","19  1377.642815               56.136590        1377.642815            1   \n","20  1339.701798               54.671981        1339.701798            1   \n","21  1077.677516               56.361198        1077.677516            1   \n","\n","    can_infer  fit_order  \n","0        True         22  \n","1        True          2  \n","2        True          7  \n","3        True         15  \n","4        True         20  \n","5        True          8  \n","6        True          3  \n","7        True         12  \n","8        True          6  \n","9        True         18  \n","10       True          5  \n","11       True         11  \n","12       True         14  \n","13       True         19  \n","14       True         16  \n","15       True          1  \n","16       True          9  \n","17       True         13  \n","18       True         21  \n","19       True         17  \n","20       True          4  \n","21       True         10  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["leaderboard_test = predictor.leaderboard(silent=True)\n","leaderboard_test"]},{"cell_type":"code","execution_count":null,"id":"de8a8b25","metadata":{"execution":{"iopub.execute_input":"2024-12-30T21:59:36.822854Z","iopub.status.busy":"2024-12-30T21:59:36.822617Z","iopub.status.idle":"2024-12-30T22:02:34.371367Z","shell.execute_reply":"2024-12-30T22:02:34.369973Z"},"papermill":{"duration":177.61688,"end_time":"2024-12-30T22:02:34.405727","exception":true,"start_time":"2024-12-30T21:59:36.788847","status":"failed"},"tags":[],"id":"de8a8b25","outputId":"a571eb6a-9b02-436c-ff2d-4b4cb74f8670"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best model by autogluon is WeightedEnsemble_L2\n","With a score of RMSLE 1.0445016491259669\n"]},{"ename":"AttributeError","evalue":"'super' object has no attribute '__sklearn_tags__'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4315e2968eff>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"8hr_log_gpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msub_autogluon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msub_autogluon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premium_amount_log'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msub_autogluon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Premium Amount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_autogluon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'premium_amount_log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msub_autogluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"premium_amount_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdecision_threshold\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m             \u001b[0mdecision_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecision_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m     def predict_proba(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mdecision_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mX_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mas_pandas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         y_pred_proba = self.predict_proba(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         y_pred_proba = self._post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m             \u001b[0my_pred_proba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_multiclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_predict_proba_model\u001b[0;34m(self, X, model, model_pred_proba_dict)\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3262\u001b[0;31m         \u001b[0mmodel_pred_proba_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_pred_proba_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3264\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mget_model_pred_proba_dict\u001b[0;34m(self, X, models, model_pred_proba_dict, model_pred_time_dict, record_pred_time, use_val_cache)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackerEnsembleModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0mpreprocess_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                 \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, normalize, record_time, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecord_time\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_aux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temperature_scalar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36m_predict_proba_internal\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_nonadaptive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36mload_child\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mchild_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/xgboost/xgboost_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path, reset_paths, verbose)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xgb_model_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;31m# Much faster to load using .ubj than .json (10x+ speedup)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xgb.ubj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xgb_model_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscikit_learn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\"\"{Booster.load_model.__doc__}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_load_model_attributes\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learner_model_param\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# binary classification is treated as regression in XGBoost.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_estimator_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"__sklearn_tags__\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0msklearn_tags_provider\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m                 \u001b[0mclass_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"_more_tags\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sklearn_tags__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"regressor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressorTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"]}],"source":["i = 0\n","models = leaderboard_test['model'].to_list()\n","best_model = models[i]\n","print(\"Best model by autogluon is\", models[i])\n","print(\"With a score of RMSLE\", np.abs(leaderboard_test[leaderboard_test['model']==best_model]['score_val'][i]))\n","\n","training = \"8hr_log_gpu\"\n","sub_autogluon = submission.copy()\n","sub_autogluon['premium_amount_log'] = predictor.predict(test_transformed, as_pandas=False, model=best_model)\n","sub_autogluon['Premium Amount'] = np.expm1(sub_autogluon['premium_amount_log'])\n","sub_autogluon.drop(columns=\"premium_amount_log\", inplace=True)\n","sub_autogluon.to_csv(f'/kaggle/working/submission.csv', index=False)"]},{"cell_type":"markdown","id":"0f204c15","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"id":"0f204c15"},"source":["# **Saving OOFs**"]},{"cell_type":"code","execution_count":null,"id":"a0c1fc36","metadata":{"execution":{"iopub.execute_input":"2024-12-30T13:41:40.819725Z","iopub.status.busy":"2024-12-30T13:41:40.819416Z","iopub.status.idle":"2024-12-30T13:41:42.469405Z","shell.execute_reply":"2024-12-30T13:41:42.468405Z","shell.execute_reply.started":"2024-12-30T13:41:40.819699Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"id":"a0c1fc36"},"outputs":[],"source":["def save_experiment_oofs(predictor, models, experiment_name, path, islog=True):\n","    \"\"\"\n","    Save OOF predictions as a single DataFrame with experiment identifier in column names\n","    \"\"\"\n","    # Create DataFrame with index from training data\n","    oof_df = pd.DataFrame(index=predictor.predict_oof().index)\n","\n","    # Add OOF predictions for each model with experiment identifier\n","    for i, model in enumerate(models, 1):\n","        print(f\"Generating OOF predictions for {model} - {i}/{len(models)}\")\n","        oof_preds = predictor.predict_oof(model=model)\n","        if islog:\n","            oof_preds = np.power(10, oof_preds)\n","        col_name = f\"{experiment_name}_{model}\"\n","        oof_df[col_name] = oof_preds\n","\n","    # Save DataFrame\n","    filename = f\"oof_preds_{experiment_name}.parquet\"\n","    filepath = os.path.join(path, filename)\n","\n","    oof_df.to_parquet(filepath)\n","    print(f\"Saved {len(models)} model predictions for experiment {experiment_name}\")\n","    return oof_df\n","\n","# Saving OOFs for later use\n","oofs_path = \"/kaggle/working/\"\n","models = leaderboard_test['model'].to_list()\n","experiment_name = \"8log\"\n","oof_df = save_experiment_oofs(predictor, models, experiment_name, oofs_path)"]},{"cell_type":"code","execution_count":null,"id":"dce99f91","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"id":"dce99f91"},"outputs":[],"source":["top_models = leaderboard_test['model'].head(5).to_list()\n","for i, model in enumerate(leaderboard_test['model'].head().to_list()):\n","    print(\"\\nModel by autogluon is\", model)\n","    print(\"With a score of RMSLE\", np.abs(leaderboard_test[leaderboard_test['model']==model]['score_val'][i]))\n","\n","    training = \"8hr_log_gpu\"\n","    sub_autogluon = submission.copy()\n","    sub_autogluon['premium_amount_log'] = predictor.predict(test_transformed, as_pandas=False, model=best_model)\n","    sub_autogluon['Premium Amount'] = np.expm1(sub_autogluon['premium_amount_log'])\n","    sub_autogluon.drop(columns=\"premium_amount_log\", inplace=True)\n","    sub_autogluon.to_csv(f'/kaggle/working/sub_{model}_{training}.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"d987500c","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"id":"d987500c"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":10305135,"sourceId":84896,"sourceType":"competition"},{"databundleVersionId":9360233,"datasetId":5547076,"sourceId":9178166,"sourceType":"datasetVersion"},{"databundleVersionId":10642285,"datasetId":6398912,"sourceId":10334731,"sourceType":"datasetVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":29208.398065,"end_time":"2024-12-30T22:02:37.389929","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-30T13:55:48.991864","version":"2.6.0"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}